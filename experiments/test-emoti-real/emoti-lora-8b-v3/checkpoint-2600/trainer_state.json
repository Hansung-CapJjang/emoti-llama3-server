{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.635459555330335,
  "eval_steps": 500,
  "global_step": 2600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05067460568822449,
      "grad_norm": 17.335718154907227,
      "learning_rate": 9.997562734789708e-05,
      "loss": 134.9594,
      "step": 50
    },
    {
      "epoch": 0.10134921137644898,
      "grad_norm": 0.8438937067985535,
      "learning_rate": 9.990053454785462e-05,
      "loss": 0.4508,
      "step": 100
    },
    {
      "epoch": 0.15202381706467347,
      "grad_norm": 0.1687425673007965,
      "learning_rate": 9.977478767476822e-05,
      "loss": 0.0507,
      "step": 150
    },
    {
      "epoch": 0.20269842275289796,
      "grad_norm": 0.042604368180036545,
      "learning_rate": 9.959851437439063e-05,
      "loss": 0.0084,
      "step": 200
    },
    {
      "epoch": 0.2533730284411224,
      "grad_norm": 0.024935487657785416,
      "learning_rate": 9.937189358189185e-05,
      "loss": 0.0051,
      "step": 250
    },
    {
      "epoch": 0.30404763412934693,
      "grad_norm": 0.020620297640562057,
      "learning_rate": 9.909515534022194e-05,
      "loss": 0.0035,
      "step": 300
    },
    {
      "epoch": 0.3547222398175714,
      "grad_norm": 0.01947408728301525,
      "learning_rate": 9.876858056659418e-05,
      "loss": 0.0026,
      "step": 350
    },
    {
      "epoch": 0.4053968455057959,
      "grad_norm": 0.015572297386825085,
      "learning_rate": 9.839250076732587e-05,
      "loss": 0.0022,
      "step": 400
    },
    {
      "epoch": 0.45607145119402037,
      "grad_norm": 0.006940238177776337,
      "learning_rate": 9.796729770132589e-05,
      "loss": 0.0018,
      "step": 450
    },
    {
      "epoch": 0.5067460568822448,
      "grad_norm": 0.006245733704417944,
      "learning_rate": 9.749340299257099e-05,
      "loss": 0.0015,
      "step": 500
    },
    {
      "epoch": 0.5574206625704694,
      "grad_norm": 0.006692888680845499,
      "learning_rate": 9.697129769196394e-05,
      "loss": 0.0013,
      "step": 550
    },
    {
      "epoch": 0.6080952682586939,
      "grad_norm": 0.006542266346514225,
      "learning_rate": 9.640151178901834e-05,
      "loss": 0.0012,
      "step": 600
    },
    {
      "epoch": 0.6587698739469183,
      "grad_norm": 0.008537760935723782,
      "learning_rate": 9.578462367386586e-05,
      "loss": 0.001,
      "step": 650
    },
    {
      "epoch": 0.7094444796351428,
      "grad_norm": 0.004662918392568827,
      "learning_rate": 9.512125955013192e-05,
      "loss": 0.001,
      "step": 700
    },
    {
      "epoch": 0.7601190853233674,
      "grad_norm": 0.007616615854203701,
      "learning_rate": 9.441209279927592e-05,
      "loss": 0.0009,
      "step": 750
    },
    {
      "epoch": 0.8107936910115918,
      "grad_norm": 0.003551607020199299,
      "learning_rate": 9.365784329704115e-05,
      "loss": 0.0008,
      "step": 800
    },
    {
      "epoch": 0.8614682966998163,
      "grad_norm": 0.00463681947439909,
      "learning_rate": 9.285927668270835e-05,
      "loss": 0.0008,
      "step": 850
    },
    {
      "epoch": 0.9121429023880407,
      "grad_norm": 0.0036999222356826067,
      "learning_rate": 9.201720358189464e-05,
      "loss": 0.0007,
      "step": 900
    },
    {
      "epoch": 0.9628175080762653,
      "grad_norm": 0.018735378980636597,
      "learning_rate": 9.113247878368683e-05,
      "loss": 0.0006,
      "step": 950
    },
    {
      "epoch": 1.014188889592703,
      "grad_norm": 0.0028161925729364157,
      "learning_rate": 9.020600037294428e-05,
      "loss": 0.0006,
      "step": 1000
    },
    {
      "epoch": 1.0648634952809273,
      "grad_norm": 0.003931999206542969,
      "learning_rate": 8.923870881865228e-05,
      "loss": 0.0005,
      "step": 1050
    },
    {
      "epoch": 1.1155381009691518,
      "grad_norm": 0.002856035251170397,
      "learning_rate": 8.82315860192512e-05,
      "loss": 0.0005,
      "step": 1100
    },
    {
      "epoch": 1.1662127066573764,
      "grad_norm": 0.003579952986910939,
      "learning_rate": 8.718565430591059e-05,
      "loss": 0.0005,
      "step": 1150
    },
    {
      "epoch": 1.2168873123456008,
      "grad_norm": 0.0026554700452834368,
      "learning_rate": 8.610197540475995e-05,
      "loss": 0.0004,
      "step": 1200
    },
    {
      "epoch": 1.2675619180338253,
      "grad_norm": 0.0022327739279717207,
      "learning_rate": 8.498164935912973e-05,
      "loss": 0.0004,
      "step": 1250
    },
    {
      "epoch": 1.31823652372205,
      "grad_norm": 0.0023191808722913265,
      "learning_rate": 8.382581341289644e-05,
      "loss": 0.0004,
      "step": 1300
    },
    {
      "epoch": 1.3689111294102743,
      "grad_norm": 0.0015430256025865674,
      "learning_rate": 8.263564085606544e-05,
      "loss": 0.0004,
      "step": 1350
    },
    {
      "epoch": 1.4195857350984988,
      "grad_norm": 0.00190630869474262,
      "learning_rate": 8.141233983376332e-05,
      "loss": 0.0003,
      "step": 1400
    },
    {
      "epoch": 1.4702603407867232,
      "grad_norm": 0.0019378862343728542,
      "learning_rate": 8.015715211984881e-05,
      "loss": 0.0003,
      "step": 1450
    },
    {
      "epoch": 1.5209349464749478,
      "grad_norm": 0.0020221974700689316,
      "learning_rate": 7.887135185638715e-05,
      "loss": 0.0003,
      "step": 1500
    },
    {
      "epoch": 1.571609552163172,
      "grad_norm": 0.002540396759286523,
      "learning_rate": 7.75562442602674e-05,
      "loss": 0.0003,
      "step": 1550
    },
    {
      "epoch": 1.6222841578513967,
      "grad_norm": 0.0017465294804424047,
      "learning_rate": 7.621316429827575e-05,
      "loss": 0.0003,
      "step": 1600
    },
    {
      "epoch": 1.6729587635396213,
      "grad_norm": 0.0034547043032944202,
      "learning_rate": 7.484347533196961e-05,
      "loss": 0.0004,
      "step": 1650
    },
    {
      "epoch": 1.7236333692278456,
      "grad_norm": 0.0020378418266773224,
      "learning_rate": 7.344856773372832e-05,
      "loss": 0.0003,
      "step": 1700
    },
    {
      "epoch": 1.7743079749160702,
      "grad_norm": 0.001612572930753231,
      "learning_rate": 7.202985747538484e-05,
      "loss": 0.0003,
      "step": 1750
    },
    {
      "epoch": 1.8249825806042947,
      "grad_norm": 0.0012925760820508003,
      "learning_rate": 7.058878469087171e-05,
      "loss": 0.0002,
      "step": 1800
    },
    {
      "epoch": 1.875657186292519,
      "grad_norm": 0.004023400600999594,
      "learning_rate": 6.912681221433991e-05,
      "loss": 0.0002,
      "step": 1850
    },
    {
      "epoch": 1.9263317919807437,
      "grad_norm": 0.0012796880910173059,
      "learning_rate": 6.764542409523471e-05,
      "loss": 0.0002,
      "step": 1900
    },
    {
      "epoch": 1.9770063976689682,
      "grad_norm": 0.0009420964051969349,
      "learning_rate": 6.614612409183589e-05,
      "loss": 0.0002,
      "step": 1950
    },
    {
      "epoch": 2.027364287071641,
      "grad_norm": 0.000979194650426507,
      "learning_rate": 6.463043414479146e-05,
      "loss": 0.0002,
      "step": 2000
    },
    {
      "epoch": 2.078038892759866,
      "grad_norm": 0.0012392731150612235,
      "learning_rate": 6.309989283219454e-05,
      "loss": 0.0002,
      "step": 2050
    },
    {
      "epoch": 2.12871349844809,
      "grad_norm": 0.0013773416867479682,
      "learning_rate": 6.155605380777145e-05,
      "loss": 0.0002,
      "step": 2100
    },
    {
      "epoch": 2.1793881041363146,
      "grad_norm": 0.0013417614391073585,
      "learning_rate": 6.000048422376654e-05,
      "loss": 0.0002,
      "step": 2150
    },
    {
      "epoch": 2.2300627098245394,
      "grad_norm": 0.0009925534250214696,
      "learning_rate": 5.843476314012469e-05,
      "loss": 0.0002,
      "step": 2200
    },
    {
      "epoch": 2.2807373155127637,
      "grad_norm": 0.000841329456306994,
      "learning_rate": 5.6860479921586285e-05,
      "loss": 0.0002,
      "step": 2250
    },
    {
      "epoch": 2.331411921200988,
      "grad_norm": 0.001298599410802126,
      "learning_rate": 5.527923262432182e-05,
      "loss": 0.0002,
      "step": 2300
    },
    {
      "epoch": 2.3820865268892124,
      "grad_norm": 0.0009395744418725371,
      "learning_rate": 5.3692626373743706e-05,
      "loss": 0.0002,
      "step": 2350
    },
    {
      "epoch": 2.432761132577437,
      "grad_norm": 0.0020346464589238167,
      "learning_rate": 5.2102271735142204e-05,
      "loss": 0.0002,
      "step": 2400
    },
    {
      "epoch": 2.4834357382656616,
      "grad_norm": 0.000762876879889518,
      "learning_rate": 5.05097830787993e-05,
      "loss": 0.0002,
      "step": 2450
    },
    {
      "epoch": 2.534110343953886,
      "grad_norm": 0.0010991187300533056,
      "learning_rate": 4.8916776941240135e-05,
      "loss": 0.0002,
      "step": 2500
    },
    {
      "epoch": 2.5847849496421107,
      "grad_norm": 0.0010297315893694758,
      "learning_rate": 4.732487038428544e-05,
      "loss": 0.0002,
      "step": 2550
    },
    {
      "epoch": 2.635459555330335,
      "grad_norm": 0.0007816533907316625,
      "learning_rate": 4.573567935357077e-05,
      "loss": 0.0002,
      "step": 2600
    }
  ],
  "logging_steps": 50,
  "max_steps": 4930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5354676043399037e+19,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
