{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.965857984417559,
  "eval_steps": 500,
  "global_step": 4900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05067460568822449,
      "grad_norm": 17.335718154907227,
      "learning_rate": 9.997562734789708e-05,
      "loss": 134.9594,
      "step": 50
    },
    {
      "epoch": 0.10134921137644898,
      "grad_norm": 0.8438937067985535,
      "learning_rate": 9.990053454785462e-05,
      "loss": 0.4508,
      "step": 100
    },
    {
      "epoch": 0.15202381706467347,
      "grad_norm": 0.1687425673007965,
      "learning_rate": 9.977478767476822e-05,
      "loss": 0.0507,
      "step": 150
    },
    {
      "epoch": 0.20269842275289796,
      "grad_norm": 0.042604368180036545,
      "learning_rate": 9.959851437439063e-05,
      "loss": 0.0084,
      "step": 200
    },
    {
      "epoch": 0.2533730284411224,
      "grad_norm": 0.024935487657785416,
      "learning_rate": 9.937189358189185e-05,
      "loss": 0.0051,
      "step": 250
    },
    {
      "epoch": 0.30404763412934693,
      "grad_norm": 0.020620297640562057,
      "learning_rate": 9.909515534022194e-05,
      "loss": 0.0035,
      "step": 300
    },
    {
      "epoch": 0.3547222398175714,
      "grad_norm": 0.01947408728301525,
      "learning_rate": 9.876858056659418e-05,
      "loss": 0.0026,
      "step": 350
    },
    {
      "epoch": 0.4053968455057959,
      "grad_norm": 0.015572297386825085,
      "learning_rate": 9.839250076732587e-05,
      "loss": 0.0022,
      "step": 400
    },
    {
      "epoch": 0.45607145119402037,
      "grad_norm": 0.006940238177776337,
      "learning_rate": 9.796729770132589e-05,
      "loss": 0.0018,
      "step": 450
    },
    {
      "epoch": 0.5067460568822448,
      "grad_norm": 0.006245733704417944,
      "learning_rate": 9.749340299257099e-05,
      "loss": 0.0015,
      "step": 500
    },
    {
      "epoch": 0.5574206625704694,
      "grad_norm": 0.006692888680845499,
      "learning_rate": 9.697129769196394e-05,
      "loss": 0.0013,
      "step": 550
    },
    {
      "epoch": 0.6080952682586939,
      "grad_norm": 0.006542266346514225,
      "learning_rate": 9.640151178901834e-05,
      "loss": 0.0012,
      "step": 600
    },
    {
      "epoch": 0.6587698739469183,
      "grad_norm": 0.008537760935723782,
      "learning_rate": 9.578462367386586e-05,
      "loss": 0.001,
      "step": 650
    },
    {
      "epoch": 0.7094444796351428,
      "grad_norm": 0.004662918392568827,
      "learning_rate": 9.512125955013192e-05,
      "loss": 0.001,
      "step": 700
    },
    {
      "epoch": 0.7601190853233674,
      "grad_norm": 0.007616615854203701,
      "learning_rate": 9.441209279927592e-05,
      "loss": 0.0009,
      "step": 750
    },
    {
      "epoch": 0.8107936910115918,
      "grad_norm": 0.003551607020199299,
      "learning_rate": 9.365784329704115e-05,
      "loss": 0.0008,
      "step": 800
    },
    {
      "epoch": 0.8614682966998163,
      "grad_norm": 0.00463681947439909,
      "learning_rate": 9.285927668270835e-05,
      "loss": 0.0008,
      "step": 850
    },
    {
      "epoch": 0.9121429023880407,
      "grad_norm": 0.0036999222356826067,
      "learning_rate": 9.201720358189464e-05,
      "loss": 0.0007,
      "step": 900
    },
    {
      "epoch": 0.9628175080762653,
      "grad_norm": 0.018735378980636597,
      "learning_rate": 9.113247878368683e-05,
      "loss": 0.0006,
      "step": 950
    },
    {
      "epoch": 1.014188889592703,
      "grad_norm": 0.0028161925729364157,
      "learning_rate": 9.020600037294428e-05,
      "loss": 0.0006,
      "step": 1000
    },
    {
      "epoch": 1.0648634952809273,
      "grad_norm": 0.003931999206542969,
      "learning_rate": 8.923870881865228e-05,
      "loss": 0.0005,
      "step": 1050
    },
    {
      "epoch": 1.1155381009691518,
      "grad_norm": 0.002856035251170397,
      "learning_rate": 8.82315860192512e-05,
      "loss": 0.0005,
      "step": 1100
    },
    {
      "epoch": 1.1662127066573764,
      "grad_norm": 0.003579952986910939,
      "learning_rate": 8.718565430591059e-05,
      "loss": 0.0005,
      "step": 1150
    },
    {
      "epoch": 1.2168873123456008,
      "grad_norm": 0.0026554700452834368,
      "learning_rate": 8.610197540475995e-05,
      "loss": 0.0004,
      "step": 1200
    },
    {
      "epoch": 1.2675619180338253,
      "grad_norm": 0.0022327739279717207,
      "learning_rate": 8.498164935912973e-05,
      "loss": 0.0004,
      "step": 1250
    },
    {
      "epoch": 1.31823652372205,
      "grad_norm": 0.0023191808722913265,
      "learning_rate": 8.382581341289644e-05,
      "loss": 0.0004,
      "step": 1300
    },
    {
      "epoch": 1.3689111294102743,
      "grad_norm": 0.0015430256025865674,
      "learning_rate": 8.263564085606544e-05,
      "loss": 0.0004,
      "step": 1350
    },
    {
      "epoch": 1.4195857350984988,
      "grad_norm": 0.00190630869474262,
      "learning_rate": 8.141233983376332e-05,
      "loss": 0.0003,
      "step": 1400
    },
    {
      "epoch": 1.4702603407867232,
      "grad_norm": 0.0019378862343728542,
      "learning_rate": 8.015715211984881e-05,
      "loss": 0.0003,
      "step": 1450
    },
    {
      "epoch": 1.5209349464749478,
      "grad_norm": 0.0020221974700689316,
      "learning_rate": 7.887135185638715e-05,
      "loss": 0.0003,
      "step": 1500
    },
    {
      "epoch": 1.571609552163172,
      "grad_norm": 0.002540396759286523,
      "learning_rate": 7.75562442602674e-05,
      "loss": 0.0003,
      "step": 1550
    },
    {
      "epoch": 1.6222841578513967,
      "grad_norm": 0.0017465294804424047,
      "learning_rate": 7.621316429827575e-05,
      "loss": 0.0003,
      "step": 1600
    },
    {
      "epoch": 1.6729587635396213,
      "grad_norm": 0.0034547043032944202,
      "learning_rate": 7.484347533196961e-05,
      "loss": 0.0004,
      "step": 1650
    },
    {
      "epoch": 1.7236333692278456,
      "grad_norm": 0.0020378418266773224,
      "learning_rate": 7.344856773372832e-05,
      "loss": 0.0003,
      "step": 1700
    },
    {
      "epoch": 1.7743079749160702,
      "grad_norm": 0.001612572930753231,
      "learning_rate": 7.202985747538484e-05,
      "loss": 0.0003,
      "step": 1750
    },
    {
      "epoch": 1.8249825806042947,
      "grad_norm": 0.0012925760820508003,
      "learning_rate": 7.058878469087171e-05,
      "loss": 0.0002,
      "step": 1800
    },
    {
      "epoch": 1.875657186292519,
      "grad_norm": 0.004023400600999594,
      "learning_rate": 6.912681221433991e-05,
      "loss": 0.0002,
      "step": 1850
    },
    {
      "epoch": 1.9263317919807437,
      "grad_norm": 0.0012796880910173059,
      "learning_rate": 6.764542409523471e-05,
      "loss": 0.0002,
      "step": 1900
    },
    {
      "epoch": 1.9770063976689682,
      "grad_norm": 0.0009420964051969349,
      "learning_rate": 6.614612409183589e-05,
      "loss": 0.0002,
      "step": 1950
    },
    {
      "epoch": 2.027364287071641,
      "grad_norm": 0.000979194650426507,
      "learning_rate": 6.463043414479146e-05,
      "loss": 0.0002,
      "step": 2000
    },
    {
      "epoch": 2.078038892759866,
      "grad_norm": 0.0012392731150612235,
      "learning_rate": 6.309989283219454e-05,
      "loss": 0.0002,
      "step": 2050
    },
    {
      "epoch": 2.12871349844809,
      "grad_norm": 0.0013773416867479682,
      "learning_rate": 6.155605380777145e-05,
      "loss": 0.0002,
      "step": 2100
    },
    {
      "epoch": 2.1793881041363146,
      "grad_norm": 0.0013417614391073585,
      "learning_rate": 6.000048422376654e-05,
      "loss": 0.0002,
      "step": 2150
    },
    {
      "epoch": 2.2300627098245394,
      "grad_norm": 0.0009925534250214696,
      "learning_rate": 5.843476314012469e-05,
      "loss": 0.0002,
      "step": 2200
    },
    {
      "epoch": 2.2807373155127637,
      "grad_norm": 0.000841329456306994,
      "learning_rate": 5.6860479921586285e-05,
      "loss": 0.0002,
      "step": 2250
    },
    {
      "epoch": 2.331411921200988,
      "grad_norm": 0.001298599410802126,
      "learning_rate": 5.527923262432182e-05,
      "loss": 0.0002,
      "step": 2300
    },
    {
      "epoch": 2.3820865268892124,
      "grad_norm": 0.0009395744418725371,
      "learning_rate": 5.3692626373743706e-05,
      "loss": 0.0002,
      "step": 2350
    },
    {
      "epoch": 2.432761132577437,
      "grad_norm": 0.0020346464589238167,
      "learning_rate": 5.2102271735142204e-05,
      "loss": 0.0002,
      "step": 2400
    },
    {
      "epoch": 2.4834357382656616,
      "grad_norm": 0.000762876879889518,
      "learning_rate": 5.05097830787993e-05,
      "loss": 0.0002,
      "step": 2450
    },
    {
      "epoch": 2.534110343953886,
      "grad_norm": 0.0010991187300533056,
      "learning_rate": 4.8916776941240135e-05,
      "loss": 0.0002,
      "step": 2500
    },
    {
      "epoch": 2.5847849496421107,
      "grad_norm": 0.0010297315893694758,
      "learning_rate": 4.732487038428544e-05,
      "loss": 0.0002,
      "step": 2550
    },
    {
      "epoch": 2.635459555330335,
      "grad_norm": 0.0007816533907316625,
      "learning_rate": 4.573567935357077e-05,
      "loss": 0.0002,
      "step": 2600
    },
    {
      "epoch": 2.6861341610185594,
      "grad_norm": 0.0008336803875863552,
      "learning_rate": 4.4150817038198825e-05,
      "loss": 0.0001,
      "step": 2650
    },
    {
      "epoch": 2.736808766706784,
      "grad_norm": 0.0009124843636527658,
      "learning_rate": 4.2571892233189834e-05,
      "loss": 0.0001,
      "step": 2700
    },
    {
      "epoch": 2.7874833723950085,
      "grad_norm": 0.0009424234740436077,
      "learning_rate": 4.1000507706392424e-05,
      "loss": 0.0001,
      "step": 2750
    },
    {
      "epoch": 2.838157978083233,
      "grad_norm": 0.0007118286448530853,
      "learning_rate": 3.943825857151276e-05,
      "loss": 0.0001,
      "step": 2800
    },
    {
      "epoch": 2.8888325837714577,
      "grad_norm": 0.0008703831117600203,
      "learning_rate": 3.78867306689132e-05,
      "loss": 0.0001,
      "step": 2850
    },
    {
      "epoch": 2.939507189459682,
      "grad_norm": 0.0011073242640122771,
      "learning_rate": 3.6347498955824583e-05,
      "loss": 0.0001,
      "step": 2900
    },
    {
      "epoch": 2.9901817951479064,
      "grad_norm": 0.0015345140127465129,
      "learning_rate": 3.48221259076058e-05,
      "loss": 0.0001,
      "step": 2950
    },
    {
      "epoch": 3.0405396845505797,
      "grad_norm": 0.0007444273214787245,
      "learning_rate": 3.331215993167379e-05,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 3.091214290238804,
      "grad_norm": 0.0007128911092877388,
      "learning_rate": 3.181913379571397e-05,
      "loss": 0.0001,
      "step": 3050
    },
    {
      "epoch": 3.1418888959270284,
      "grad_norm": 0.005200346931815147,
      "learning_rate": 3.034456307176644e-05,
      "loss": 0.0001,
      "step": 3100
    },
    {
      "epoch": 3.192563501615253,
      "grad_norm": 0.000788122124504298,
      "learning_rate": 2.8889944597767617e-05,
      "loss": 0.0001,
      "step": 3150
    },
    {
      "epoch": 3.2432381073034775,
      "grad_norm": 0.000660111487377435,
      "learning_rate": 2.7456754958108845e-05,
      "loss": 0.0001,
      "step": 3200
    },
    {
      "epoch": 3.293912712991702,
      "grad_norm": 0.0009096898720599711,
      "learning_rate": 2.604644898475437e-05,
      "loss": 0.0001,
      "step": 3250
    },
    {
      "epoch": 3.3445873186799266,
      "grad_norm": 0.0005505972658284009,
      "learning_rate": 2.4660458280440253e-05,
      "loss": 0.0001,
      "step": 3300
    },
    {
      "epoch": 3.395261924368151,
      "grad_norm": 0.0006286570569500327,
      "learning_rate": 2.3300189765453196e-05,
      "loss": 0.0001,
      "step": 3350
    },
    {
      "epoch": 3.4459365300563753,
      "grad_norm": 0.0008724980871193111,
      "learning_rate": 2.196702424946474e-05,
      "loss": 0.0001,
      "step": 3400
    },
    {
      "epoch": 3.4966111357446,
      "grad_norm": 0.000944645085837692,
      "learning_rate": 2.066231502987018e-05,
      "loss": 0.0001,
      "step": 3450
    },
    {
      "epoch": 3.5472857414328245,
      "grad_norm": 0.0021570962853729725,
      "learning_rate": 1.938738651805525e-05,
      "loss": 0.0001,
      "step": 3500
    },
    {
      "epoch": 3.597960347121049,
      "grad_norm": 0.0007222837884910405,
      "learning_rate": 1.81435328949851e-05,
      "loss": 0.0001,
      "step": 3550
    },
    {
      "epoch": 3.6486349528092736,
      "grad_norm": 0.001338443486019969,
      "learning_rate": 1.693201679748016e-05,
      "loss": 0.0001,
      "step": 3600
    },
    {
      "epoch": 3.699309558497498,
      "grad_norm": 0.0007545214612036943,
      "learning_rate": 1.5754068036512464e-05,
      "loss": 0.0001,
      "step": 3650
    },
    {
      "epoch": 3.7499841641857223,
      "grad_norm": 0.0005395489861257374,
      "learning_rate": 1.461088234882354e-05,
      "loss": 0.0001,
      "step": 3700
    },
    {
      "epoch": 3.800658769873947,
      "grad_norm": 0.0011987797915935516,
      "learning_rate": 1.3503620183131032e-05,
      "loss": 0.0001,
      "step": 3750
    },
    {
      "epoch": 3.8513333755621715,
      "grad_norm": 0.0006206260877661407,
      "learning_rate": 1.2433405522156332e-05,
      "loss": 0.0001,
      "step": 3800
    },
    {
      "epoch": 3.902007981250396,
      "grad_norm": 0.002103643026202917,
      "learning_rate": 1.1401324741668795e-05,
      "loss": 0.0001,
      "step": 3850
    },
    {
      "epoch": 3.9526825869386206,
      "grad_norm": 0.0006975915748625994,
      "learning_rate": 1.0408425507704766e-05,
      "loss": 0.0001,
      "step": 3900
    },
    {
      "epoch": 4.003040476341294,
      "grad_norm": 0.0005092416540719569,
      "learning_rate": 9.455715713080976e-06,
      "loss": 0.0001,
      "step": 3950
    },
    {
      "epoch": 4.053715082029518,
      "grad_norm": 0.0007580106612294912,
      "learning_rate": 8.544162454281757e-06,
      "loss": 0.0001,
      "step": 4000
    },
    {
      "epoch": 4.104389687717743,
      "grad_norm": 0.0006713481270708144,
      "learning_rate": 7.67469104975857e-06,
      "loss": 0.0001,
      "step": 4050
    },
    {
      "epoch": 4.155064293405967,
      "grad_norm": 0.0007690133643336594,
      "learning_rate": 6.848184100638483e-06,
      "loss": 0.0001,
      "step": 4100
    },
    {
      "epoch": 4.205738899094191,
      "grad_norm": 0.0006539392052218318,
      "learning_rate": 6.065480594795114e-06,
      "loss": 0.0001,
      "step": 4150
    },
    {
      "epoch": 4.256413504782416,
      "grad_norm": 0.0007318984135054052,
      "learning_rate": 5.327375055191314e-06,
      "loss": 0.0001,
      "step": 4200
    },
    {
      "epoch": 4.30708811047064,
      "grad_norm": 0.0008940797997638583,
      "learning_rate": 4.634616733358282e-06,
      "loss": 0.0001,
      "step": 4250
    },
    {
      "epoch": 4.357762716158865,
      "grad_norm": 0.0009981546318158507,
      "learning_rate": 3.987908848829702e-06,
      "loss": 0.0001,
      "step": 4300
    },
    {
      "epoch": 4.40843732184709,
      "grad_norm": 0.0009297732613049448,
      "learning_rate": 3.3879078753030536e-06,
      "loss": 0.0001,
      "step": 4350
    },
    {
      "epoch": 4.4591119275353135,
      "grad_norm": 0.000549341959413141,
      "learning_rate": 2.8352228742526243e-06,
      "loss": 0.0001,
      "step": 4400
    },
    {
      "epoch": 4.509786533223538,
      "grad_norm": 0.0005186632042750716,
      "learning_rate": 2.330414876670728e-06,
      "loss": 0.0001,
      "step": 4450
    },
    {
      "epoch": 4.560461138911763,
      "grad_norm": 0.0006222259253263474,
      "learning_rate": 1.8739963135646299e-06,
      "loss": 0.0001,
      "step": 4500
    },
    {
      "epoch": 4.611135744599987,
      "grad_norm": 0.0008025123970583081,
      "learning_rate": 1.4664304957875018e-06,
      "loss": 0.0001,
      "step": 4550
    },
    {
      "epoch": 4.661810350288212,
      "grad_norm": 0.001113289501518011,
      "learning_rate": 1.1081311437311282e-06,
      "loss": 0.0001,
      "step": 4600
    },
    {
      "epoch": 4.712484955976437,
      "grad_norm": 0.001171681797131896,
      "learning_rate": 7.994619673580561e-07,
      "loss": 0.0001,
      "step": 4650
    },
    {
      "epoch": 4.7631595616646605,
      "grad_norm": 0.001157868537120521,
      "learning_rate": 5.407362969992558e-07,
      "loss": 0.0001,
      "step": 4700
    },
    {
      "epoch": 4.813834167352885,
      "grad_norm": 0.0006019636639393866,
      "learning_rate": 3.322167652923092e-07,
      "loss": 0.0001,
      "step": 4750
    },
    {
      "epoch": 4.86450877304111,
      "grad_norm": 0.0006841393769718707,
      "learning_rate": 1.7411504058277294e-07,
      "loss": 0.0001,
      "step": 4800
    },
    {
      "epoch": 4.915183378729334,
      "grad_norm": 0.0006202394142746925,
      "learning_rate": 6.659161205948006e-08,
      "loss": 0.0001,
      "step": 4850
    },
    {
      "epoch": 4.965857984417559,
      "grad_norm": 0.0005871746107004583,
      "learning_rate": 9.755626841823074e-09,
      "loss": 0.0001,
      "step": 4900
    }
  ],
  "logging_steps": 50,
  "max_steps": 4930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.893200940004593e+19,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
